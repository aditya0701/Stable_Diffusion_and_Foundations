{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e320889-b21b-4a07-9419-2b007394ec57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    WARNING: No metadata found in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages\n",
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'c:\\\\users\\\\adima\\\\anaconda3\\\\envs\\\\d2l\\\\lib\\\\site-packages\\\\transformers-4.24.0.dist-info\\\\'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install -q --upgrade transformers diffusers ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2be56f5-a134-4692-9701-c7a798b0a74e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'diffusers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoencoderKL, LMSDiscreteScheduler, UNet2DConditionModel\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m notebook_login\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# For video display:\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'diffusers'"
     ]
    }
   ],
   "source": [
    "from base64 import b64decode\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "\n",
    "from diffusers import AutoencoderKL, LMSDiscreteScheduler, UNet2DConditionModel\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# For video display:\n",
    "from IPython.display import HTML\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch import autocast\n",
    "from torchvision import transforms as tfms\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import CLIPTextModel, CLIPTokenizer, logging\n",
    "\n",
    "torch.manual_seed(1)\n",
    "if not (Path.home()/'.huggingface'/'token').exists(): notebook_login()\n",
    "\n",
    "# Supress some unnecessary warnings when loading the CLIPTextModel\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# Set device\n",
    "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dee6b8-8a51-45b2-a565-590f13baa218",
   "metadata": {},
   "source": [
    "## Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52f08155-663e-4ac0-b20f-7e2c5d4cf13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = AutoencoderKL.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder = 'vae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65e1bc70-8d42-4f1c-9e56-df4f2a5fabe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a086b2b91c4788919a5f581c6c569d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/961k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cdfd45812ae44e8b234b59be93c929f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b02613a224d4cc2bfd80c24734ccc07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45573369eda0441f9d00756e2b4b8d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/905 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6fbc738e4cc47399ca6c8b16b0ce3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/4.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5794dac55f874cc0b4b235d1cc86187b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "633abdd9-55fc-4a99-bab4-990e96bd2330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f9494c46024f9ca25ce0317a77e641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ain/unet/config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2344252f9d2e417eb5fd3e4b1086ea7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ch_model.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unet = UNet2DConditionModel.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"unet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a0e8d2-1b37-4a0c-aac3-27aac7465730",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
    "\n",
    "# To the GPU we go!\n",
    "vae = vae.to(torch_device)\n",
    "text_encoder = text_encoder.to(torch_device)\n",
    "unet = unet.to(torch_device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbc1101-106b-438c-9ccb-f2b5e9babebd",
   "metadata": {},
   "source": [
    "## Diffusion Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df799b4c-0b90-40b4-97cc-9ecdc61b87cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\"A watercolor painting of an platypus\"]\n",
    "height = 512                        # default height of Stable Diffusion\n",
    "width = 512                         # default width of Stable Diffusion\n",
    "num_inference_steps = 30            # Number of denoising steps\n",
    "guidance_scale = 7.5                # Scale for classifier-free guidance\n",
    "generator = torch.manual_seed(32)   # Seed generator to create the inital latent noise\n",
    "batch_size = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01c2a18e-cda8-4fba-b99f-1018aff82e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing the text\n",
    "text_input = tokenizer(prompt, padding='max_length', max_length=tokenizer.model_max_length,truncation=True, \n",
    "                       return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    text_embeddings = text_encoder(text_input.input_ids.to(torch_device))[0]\n",
    "max_length = text_input.input_ids.shape[-1]\n",
    "uncond_input = tokenizer(\n",
    "    [\"\"] * batch_size, padding = \"max_length\", max_length=max_length, return_tensors=\"pt\"\n",
    ")\n",
    "with torch.no_grad():\n",
    "    uncond_embeddings = text_encoder(uncond_input.input_ids.to(torch_device))[0]\n",
    "text_embeddings = torch.cat([uncond_embeddings,text_embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f19964c9-17e1-4b8b-a494-654757ca334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the Scheduler\n",
    "scheduler.set_timesteps(num_inference_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7978f2de-5e79-4fb9-a5a8-2ad8aabf85f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep latents\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
