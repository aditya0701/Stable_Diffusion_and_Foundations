{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e320889-b21b-4a07-9419-2b007394ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --upgrade transformers diffusers ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "776ca5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "Requirement already satisfied: filelock in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from transformers) (3.10.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from requests->transformers) (2023.5.7)\n",
      "Installing collected packages: transformers\n",
      "Successfully installed transformers-4.30.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2be56f5-a134-4692-9701-c7a798b0a74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cde1eb071184cc2ac44e092658e6170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e444cc4ae774e36985f11a93865875d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from base64 import b64decode\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "\n",
    "from diffusers import AutoencoderKL, LMSDiscreteScheduler, UNet2DConditionModel\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# For video display:\n",
    "from IPython.display import HTML\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch import autocast\n",
    "from torchvision import transforms as tfms\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import CLIPTextModel, CLIPTokenizer, logging\n",
    "\n",
    "torch.manual_seed(1)\n",
    "if not (Path.home()/'.huggingface'/'token').exists(): notebook_login()\n",
    "\n",
    "# Supress some unnecessary warnings when loading the CLIPTextModel\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# Set device\n",
    "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dee6b8-8a51-45b2-a565-590f13baa218",
   "metadata": {},
   "source": [
    "## Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52f08155-663e-4ac0-b20f-7e2c5d4cf13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8c972646cc4dcf89e7325c2bcec2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)main/vae/config.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\adima\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6afefa42f7104512b1ef85670bd5d3e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vae = AutoencoderKL.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder = 'vae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bc5ab43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
      "                                              0.0/227.6 kB ? eta -:--:--\n",
      "     -                                        10.2/227.6 kB ? eta -:--:--\n",
      "     -                                        10.2/227.6 kB ? eta -:--:--\n",
      "     -                                        10.2/227.6 kB ? eta -:--:--\n",
      "     -                                        10.2/227.6 kB ? eta -:--:--\n",
      "     -                                        10.2/227.6 kB ? eta -:--:--\n",
      "     ----------------------               143.4/227.6 kB 502.3 kB/s eta 0:00:01\n",
      "     ----------------------               143.4/227.6 kB 502.3 kB/s eta 0:00:01\n",
      "     ---------------------------          174.1/227.6 kB 499.5 kB/s eta 0:00:01\n",
      "     ------------------------------       194.6/227.6 kB 472.6 kB/s eta 0:00:01\n",
      "     --------------------------------     204.8/227.6 kB 461.0 kB/s eta 0:00:01\n",
      "     --------------------------------     204.8/227.6 kB 461.0 kB/s eta 0:00:01\n",
      "     -----------------------------------  225.3/227.6 kB 393.1 kB/s eta 0:00:01\n",
      "     ------------------------------------ 227.6/227.6 kB 386.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from accelerate) (2.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from torch>=1.6.0->accelerate) (3.10.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from torch>=1.6.0->accelerate) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\adima\\anaconda3\\envs\\d2l\\lib\\site-packages (from sympy->torch>=1.6.0->accelerate) (1.2.1)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65e1bc70-8d42-4f1c-9e56-df4f2a5fabe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a09127f4874bfb90df54f554a35914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/961k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf32a99bf45c4b46beb2c23546271c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcccdd04539642dd91ba671b5f2dc66f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afffb5dfbe7247acac7a81322f920472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/905 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb26a208fbde4281ad4cfcbfce4d3b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/4.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44193e37d8b48e487e9f8c5db7406eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "633abdd9-55fc-4a99-bab4-990e96bd2330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49fd35adf2914fc7a9eef9145f3cb519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ain/unet/config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b780db99d64bad846dd5293aa773ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ch_model.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unet = UNet2DConditionModel.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"unet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19a0e8d2-1b37-4a0c-aac3-27aac7465730",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
    "\n",
    "# To the GPU we go!\n",
    "vae = vae.to(torch_device)\n",
    "text_encoder = text_encoder.to(torch_device)\n",
    "unet = unet.to(torch_device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbc1101-106b-438c-9ccb-f2b5e9babebd",
   "metadata": {},
   "source": [
    "## Diffusion Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df799b4c-0b90-40b4-97cc-9ecdc61b87cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\"A watercolor painting of an platypus\"]\n",
    "height = 512                        # default height of Stable Diffusion\n",
    "width = 512                         # default width of Stable Diffusion\n",
    "num_inference_steps = 30            # Number of denoising steps\n",
    "guidance_scale = 7.5                # Scale for classifier-free guidance\n",
    "generator = torch.manual_seed(32)   # Seed generator to create the inital latent noise\n",
    "batch_size = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01c2a18e-cda8-4fba-b99f-1018aff82e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing the text\n",
    "text_input = tokenizer(prompt, padding='max_length', max_length=tokenizer.model_max_length,truncation=True, \n",
    "                       return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    text_embeddings = text_encoder(text_input.input_ids.to(torch_device))[0]\n",
    "max_length = text_input.input_ids.shape[-1]\n",
    "uncond_input = tokenizer(\n",
    "    [\"\"] * batch_size, padding = \"max_length\", max_length=max_length, return_tensors=\"pt\"\n",
    ")\n",
    "with torch.no_grad():\n",
    "    uncond_embeddings = text_encoder(uncond_input.input_ids.to(torch_device))[0]\n",
    "text_embeddings = torch.cat([uncond_embeddings,text_embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f19964c9-17e1-4b8b-a494-654757ca334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the Scheduler\n",
    "scheduler.set_timesteps(num_inference_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7978f2de-5e79-4fb9-a5a8-2ad8aabf85f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prep latents\n",
    "latents = torch.randn(\n",
    "    (batch_size, unet.config.in_channels, height // 8, width//8),\n",
    "    generator = generator,\n",
    ")\n",
    "letents = latents.to(torch_device)\n",
    "latents = latents * scheduler.init_noise_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0315efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ef87ef70ab4905b6426f32fa851036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Creating a Loop\n",
    "with autocast('cuda'):\n",
    "    for i, t in tqdm(enumerate(scheduler.timesteps)):\n",
    "        latent_model_input = torch.cat([latents] *2)\n",
    "        sigma = scheduler.sigmas[i]\n",
    "        latent_model_input = scheduler.scale_model_input(latent_model_input, t)\n",
    "        latent_model_input = latent_model_input.to(torch_device)\n",
    "        # to preduct residual noise\n",
    "        with torch.no_grad():\n",
    "            noise_pred = unet(latent_model_input, t, encoder_hidden_states = text_embeddings).sample\n",
    "        \n",
    "        #perform guidance\n",
    "        noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
    "        noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
    "        noise_pred=noise_pred.to(torch_device)\n",
    "        latents = scheduler.step(noise_pred,t.to(torch_device),latents.to(torch_device)).prev_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d77c4d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = 1 / 0.18215 * latents\n",
    "with torch.no_grad():\n",
    "    image = vae.decode(latents).sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a7865e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adima\\AppData\\Local\\Temp\\ipykernel_7868\\859665460.py:3: RuntimeWarning: invalid value encountered in cast\n",
      "  images = (image * 250).round().astype(\"uint8\")\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAIACAIAAAB7GkOtAAADEUlEQVR4nO3BgQAAAADDoPlTX+EAVQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBvArQAAVkUTe8AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=512x512>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = (image / 2 + 0.5).clamp(0, 1)\n",
    "image = image.detach().cpu().permute(0, 2, 3, 1).numpy()\n",
    "images = (image * 250).round().astype(\"uint8\")\n",
    "pil_images = [Image.fromarray(image) for image in images]\n",
    "pil_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293a47b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
